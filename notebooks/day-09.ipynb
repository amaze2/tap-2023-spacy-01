{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Firstname Lastname](https://) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
    "\n",
    "For questions/comments/improvements, email author@email.address.<br />\n",
    "____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# `spaCy 3` `1`\n",
    "\n",
    "This is lesson `1` of 3 in the educational series on `spaCy and NLP`. This notebook is intended `to teach the spaCy EntityRuler and the basics of Rules-Based NLP`. \n",
    "\n",
    "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** `Tutorial` / `How-To` / `Explanation` \n",
    "\n",
    "`Include the use case definition from [here](https://constellate.org/docs/documentation-categories)`\n",
    "\n",
    "**Difficulty:** `Intermediate`\n",
    "\n",
    "`Beginner assumes users are relatively new to Python and Jupyter Notebooks. The user is helped step-by-step with lots of explanatory text.`\n",
    "`Intermediate assumes users are familiar with Python and have been programming for 6+ months. Code makes up a larger part of the notebook and basic concepts related to Python are not explained.`\n",
    "`Advanced assumes users are very familiar with Python and have been programming for years, but they may not be familiar with the process being explained.`\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
    "* A basic understanding of spaCy (see notebooks 1-3)\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "* Basic file operations (open, close, read, write)\n",
    "* Loading data with Pandas\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Learn about the basics of supervised learning and the machine learning components in spaCy\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a220f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: setuptools in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.11.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-lg==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from en-core-web-lg==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.21.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/wjbmattingly/anaconda3/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.11.3)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# ### Install Libraries ###\n",
    "\n",
    "# # Using !pip installs\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n",
    "\n",
    "# # Using %%bash magic with apt-get and yes prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import srsly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56dfc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Next day Frodo woke early, feeling refreshed and well. He walked along the terraces above the loud-flowing Bruinen and watched the pale, cool sun rise above the far mountains, and shine down. Slanting through the thin silver mist; the dew upon the ye'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/lotr.txt\", \"r\") as f:\n",
    "    text = f.read().strip()\n",
    "text[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbfbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjbmattingly/anaconda3/lib/python3.7/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.6.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73de3bf7",
   "metadata": {},
   "source": [
    "# How to Choose Labels?\n",
    "\n",
    "When training a machine learning model, it is important to understand that this will be a trial-and-error process. This is true for all levels of training a model and the reason for this is because any time you are seeking to create a model to do something, you are creating something unique. Often times you are working with training data that you have cultivated that has not been used to train another model before. In order to figure out the right training data, the right model architecture, and the right labels, you must perform a series of tests.\n",
    "\n",
    "One of the things that is not given enough consideration frequently are the labels you choose. Remember, the labels are the ways in which you want to classify your documents. When choosing labels it is important to remember that if your labels are difficult for you to explain and differentiate to another human, this will likely be a major issue. This is a good indication that your label distinctions potentially overlap conceptually. This will lead to two major issues. First, it will mean that your annotators (or even you) will have a hard time consistently labeling the data. Second, it will mean that the model will likely struggle in being able to identify these distinctions that you want to identify.\n",
    "\n",
    "When creating labels, it is best to have labels that are clearly and conceptually distinct from one another. This does not mean that they cannot be part of a similar larger, category. In a current project, we are seeking to classify different types of places and how they appear in Holocaust oral testimonies. Our different types of places are clear and distinct however. Some are `ENVIRONMENTAL_FEATURE`, such as rivers and forests, while others are `POPULATED_PLACE`, such as a city or a ghetto, and others are labels such as `INTERIOR` to indicate a place that is inside another location. We have many other types of place labels we are using but each is distinct with few labels having cross-overs.\n",
    "\n",
    "It is equally important to consider the ethics behind your labels. Just because you can train a machine learning model to do something does not mean you should. A good example of this is a project rooted in violence in 20th century South Africa. We were interested in understanding victim-perpetrator relationships in oral testimonies. In order to do this, we need to be able to identify the victim in a text and then identify the perpetrator. There are ways to do this via machine learning. However, were we to train a model that could label VICTIM and PERPETRATOR as distinct entities, it may be right a certain percentage of the time. But what about the times its wrong? What if this model was given to the public to use? What if it made a wrong prediction and that output was not verified and instead used in a negative way? These are the questions that you should ask when cultivating labels.\n",
    "\n",
    "When constructing labels, therefore, consider these aspects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8925f30",
   "metadata": {},
   "source": [
    "# Using spaCy to Cultivate Training Data\n",
    "\n",
    "When creating training data, it is important to use annotation software. There are many available. I personally use Prodigy, which comes from the creators of spaCy. It has a higher cost than its competitors, but it is far superior since it is designed to work specifically with spaCy. It makes the process of annotation-training seamless. It also has a very good research license that you can apply for.\n",
    "\n",
    "In this part of the notebook, I will demonstrate a trick that you can do, however, to use an EntityRuler (or SpanRuler), to assist in the cultivation of a quick dataset. The goal of this process is to not train a perfect model, rather a model that is good enough to then help in the annotation process in Prodigy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4cf8179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Next day Frodo woke early, feeling refreshed and well. He walked along the terraces above the loud-flowing Bruinen and watched the pale, cool sun rise above the far mountains, and shine down. Slanting through the thin silver mist; the dew upon the ye'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/lotr.txt\", \"r\") as f:\n",
    "    text = f.read().strip()\n",
    "text[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a49522",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_hobbit\", disable=\"span_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b35eb8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Next day \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HOBBIT</span>\n",
       "</mark>\n",
       " woke early, feeling refreshed and well. He walked along the terraces above the loud-flowing Bruinen and watched the pale, cool sun rise above the far mountains, and shine down. Slanting through the thin silver mist; the dew upon the yellow leaves was glimmering, and the woven nets of gossamer twinkled on every bush. Sam walked beside him, saying nothing. but sniffing the air, and looking every now and again with wonder in his eyes at the great heights in the East. The snow was white upon their peaks.</br>     On a seat cut in the stone beside a turn in the path they came upon \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">AINUR</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HOBBIT</span>\n",
       "</mark>\n",
       " deep in talk. `Hullo! Good morning!' said \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HOBBIT</span>\n",
       "</mark>\n",
       ". `Feel ready for the great council?'</br>     `I feel ready for anything,' answered \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HOBBIT</span>\n",
       "</mark>\n",
       ". `But most of all I should like to go walking today and explore the valley. I should like to get into those pine-woods up there.' He pointed away far up the side of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rivendell\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REALM</span>\n",
       "</mark>\n",
       " to the north.</br>     'You may have a chance later,' said \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">AINUR</span>\n",
       "</mark>\n",
       ". `But we cannot </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(text[:1000])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e5959e4",
   "metadata": {},
   "source": [
    "# Creating some Non-Annotated Training Data\n",
    "\n",
    "In order to understand how to take data from JSON format (a format often outputted by annotation software like Doccano or Label Studio), you need to be familiar with how to manually create a Doc container. In this section, we will cover this as well as some methodological considerations for merging our labels into two labels: PERSON and REALM.\n",
    "\n",
    "To do this, we will need a spaCy pipeline that can generate our sentences. We will then use the Hobbit spaCy pipeline to annotate our data. First, let's make our sentencizer pipeline with the `en_core_web_sm` model and disable the NER pipe so that it runs more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5674f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjbmattingly/anaconda3/lib/python3.7/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.6.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp2 = spacy.load('en_core_web_sm', disable=\"ner\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "689080d7",
   "metadata": {},
   "source": [
    "Now that we have our sentence pipeline, we can create a doc object called `doc2`. We only want to use this document to just iterate over the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp2(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dc5ca80",
   "metadata": {},
   "source": [
    "At this stage, we have our doc2 object that contains doc2.sents (the sentences that we will use for our training data) To convert each sentence into annotated data, we will use the `sent.text` and give that to our Hobbit spaCy pipeline.\n",
    "\n",
    "First, we will initialize an empty list to store the training data.\n",
    "\n",
    "```python\n",
    "training_data = []\n",
    "```\n",
    "\n",
    "Next, we will iterate over each sentence (`sent`) in the given document (`doc2`).\n",
    "\n",
    "```python\n",
    "for sent in doc2.sents:\n",
    "```\n",
    "\n",
    "Within this loop, we will initialize an empty list to store the entities found in the current sentence.\n",
    "```python\n",
    "    ents = []\n",
    "```\n",
    "\n",
    "Within this loop, we will also create a spaCy `Doc` object by processing the text of the current sentence with the spaCy model (`nlp`). This will allow us to access information about the named entities in the sentence.\n",
    "\n",
    "```python\n",
    "    doc = nlp(sent.text)\n",
    "```\n",
    "\n",
    "Once we have our doc container, we can iterate over the named entities (`ent`) found in the current sentence. If the entity label is one of the specified labels (\"HOBBIT\", \"DWARF\", \"MAN\", \"AINUR\", \"ELF\"), it is classified as a \"PERSON\". Otherwise, it is classified as a \"REALM\". Here, we are interested in merging all races into a single label of PERSON. The goal here is to make the problem of NER easier to solve. It is easier for the model to learn the features of PERSON than 5 distinct races, especially when working with minimal training data.\n",
    "\n",
    "```python\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"HOBBIT\", \"DWARF\", \"MAN\", \"AINUR\", \"ELF\"]:\n",
    "            ents.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": \"PERSON\"})\n",
    "        else:\n",
    "            ents.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": \"REALM\"})\n",
    "```\n",
    "\n",
    "I also know that there are some missed true positives, namely Sam and Strider, so I want to ignore training data that contains these names. In this line, I state that if the names \"Sam\" and \"Strider\" are not in the current sentence's text, then use that sentence in the training data.\n",
    "\n",
    "```python\n",
    "    if \"Sam\" not in sent.text and \"Strider\" not in sent.text:\n",
    "```\n",
    "\n",
    "If there are any entities in the current sentence, add it to the training data. Additionally, if the name \"Arwen\" is in the current sentence, print the sentence. I want to illustrate here that Arwen does not appear anywhere in our training data. This will be important down below.\n",
    "\n",
    "```python\n",
    "        if ents:\n",
    "            if \"Arwen\" in sent.text:\n",
    "                print(sent)\n",
    "            training_data.append({\"text\": sent.text, \"ents\": ents})\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea30ee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "for sent in doc2.sents:\n",
    "    ents = []\n",
    "    doc = nlp(sent.text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"HOBBIT\", \"DWARF\", \"MAN\", \"AINUR\", \"ELF\"]:\n",
    "            ents.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": \"PERSON\"})\n",
    "        else:\n",
    "            ents.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": \"REALM\"})\n",
    "    if \"Sam\" not in sent.text and \"Strider\" not in sent.text:\n",
    "        if ents:\n",
    "            if \"Arwen\" in sent.text:\n",
    "                print(sent)\n",
    "            training_data.append({\"text\": sent.text, \"ents\": ents})\n",
    "print(len(training_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e54cfef",
   "metadata": {},
   "source": [
    "In this example, we are only grabbing training data that has entities present. We are ignoring the other sentences. Let's take a look at our first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98174cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Next day Frodo woke early, feeling refreshed and well.',\n",
       " 'ents': [{'start': 9, 'end': 14, 'label': 'PERSON'}]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46d88446",
   "metadata": {},
   "source": [
    "Now that we have our data, let's go ahead and create a train/validation split using the same sklearn function as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dd566c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 80\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(training_data, test_size=0.20, random_state=42)\n",
    "\n",
    "print(len(train), len(valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e61d140b",
   "metadata": {},
   "source": [
    "# Converting JSON to .spacy Format\n",
    "\n",
    "In order to train a spaCy model in spaCy 3x, there are a few steps that must be done. First, we must convert our JSON data into .spacy. We will do this with a custom function. This function is a modification of the one provided by spaCy.\n",
    "\n",
    "\n",
    "First, we need to create the function. This will be called `json2spacy` that takes training data in JSON format and converts it to spaCy's binary format, saving it to a file. The function takes three arguments: `training_data`, `annotation_key`, and `output_file`. The annotation key is the key in the dictionary where the annotations sit. In our case, this is `ents`. It also takes the `output_file`, this is the .spacy file to which you wish to dump the data.\n",
    "\n",
    "```python\n",
    "def json2spacy(training_data, annotation_key, output_file):\n",
    "```\n",
    "\n",
    "THe first thing this function does is create a blank English model using spaCy. This will be used to process the text and create `Doc` objects.\n",
    "\n",
    "```python\n",
    "    nlp = spacy.blank(\"en\")\n",
    "```\n",
    "\n",
    "Next, we initalize a `DocBin` object. `DocBin` is a container class in spaCy used to efficiently collect multiple `Doc` objects, which can be saved to disk in binary format.\n",
    "\n",
    "```python\n",
    "    db = DocBin()\n",
    "```\n",
    "\n",
    "Now, we can begin to iterate over each sample in the `training_data`. A sample contains the text and its corresponding annotations.\n",
    "\n",
    "```python\n",
    "    for sample in training_data:\n",
    "```\n",
    "\n",
    "Extract the text from the current sample.\n",
    "\n",
    "```python\n",
    "        text = sample[\"text\"]\n",
    "```\n",
    "\n",
    "Extract the annotations using the provided `annotation_key` (e.g., \"ents\").\n",
    "\n",
    "```python\n",
    "        annotations = sample[annotation_key]\n",
    "```\n",
    "\n",
    "Create a `Doc` object by processing the text with the blank English model.\n",
    "\n",
    "```python\n",
    "        doc = nlp(text)\n",
    "```\n",
    "\n",
    "Initialize an empty list to store the entity spans.\n",
    "\n",
    "```python\n",
    "        ents = []\n",
    "```\n",
    "\n",
    "Iterate over the annotations, creating a span for each one and adding it to the `ents` list.\n",
    "\n",
    "```python\n",
    "        for annotation in annotations:\n",
    "            start = annotation[\"start\"]\n",
    "            end = annotation[\"end\"]\n",
    "            label = annotation[\"label\"]\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "```\n",
    "\n",
    "Add the `doc` to the `DocBin`.\n",
    "\n",
    "```python\n",
    "        db.add(doc)\n",
    "```\n",
    "\n",
    "Save the `DocBin` to disk using the provided `output_file` path.\n",
    "\n",
    "```python\n",
    "    db.to_disk(output_file)\n",
    "```\n",
    "\n",
    "Call the `json2spacy` function twice, once for training data (`train`) and once for validation data (`valid`), specifying the output file paths.\n",
    "\n",
    "```python\n",
    "json2spacy(train, \"ents\", \"../data/train.spacy\")\n",
    "json2spacy(valid, \"ents\", \"../data/valid.spacy\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "33cec5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json2spacy(training_data, annotation_key, output_file):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for sample in training_data:\n",
    "        text = sample[\"text\"]\n",
    "        annotations = sample[annotation_key]\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for annotation in annotations:\n",
    "            start = annotation[\"start\"]\n",
    "            end = annotation[\"end\"]\n",
    "            label = annotation[\"label\"]\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_file)\n",
    "json2spacy(train, \"ents\", \"../data/train.spacy\")\n",
    "json2spacy(valid,  \"ents\", \"../data/valid.spacy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8cca1a",
   "metadata": {},
   "source": [
    "# Training without Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bb8ad746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "../data/config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ../data/base_config.cfg ../data/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aeb0f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: ../models/output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-08-04 06:28:28,806] [INFO] Set up nlp object from config\n",
      "[2023-08-04 06:28:28,815] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-08-04 06:28:28,819] [INFO] Created vocabulary\n",
      "[2023-08-04 06:28:28,819] [INFO] Finished initializing nlp object\n",
      "[2023-08-04 06:28:29,030] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     24.20    0.00    0.00    0.00    0.00\n",
      "  2     200         20.54    969.02   93.02   90.91   95.24    0.93\n",
      "  5     400          0.04      0.05   93.95   91.82   96.19    0.94\n",
      "  9     600          0.00      0.00   93.46   91.74   95.24    0.93\n",
      " 15     800          0.00      0.00   93.46   91.74   95.24    0.93\n",
      " 21    1000          0.00      0.00   95.24   95.24   95.24    0.95\n",
      " 29    1200          4.52      3.31   93.90   92.59   95.24    0.94\n",
      " 38    1400         51.63     18.69   94.79   94.34   95.24    0.95\n",
      " 50    1600         12.03      4.99   96.62   98.04   95.24    0.97\n",
      " 64    1800         24.56      6.83   96.62   98.04   95.24    0.97\n",
      " 81    2000          0.00      0.00   96.62   98.04   95.24    0.97\n",
      "102    2200         17.15      3.96   94.34   93.46   95.24    0.94\n",
      "127    2400          0.00      0.00   94.34   93.46   95.24    0.94\n",
      "152    2600          0.07      0.02   94.34   93.46   95.24    0.94\n",
      "177    2800          0.00      0.00   94.34   93.46   95.24    0.94\n",
      "202    3000          0.00      0.00   94.34   93.46   95.24    0.94\n",
      "227    3200          0.00      0.00   94.34   93.46   95.24    0.94\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "../models/output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../data/config.cfg --output ../models/output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8bc533d",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "In machine learning, we have multiple ways to convey accuracy. Let's look at 3 types right now: precision, recall, and f-score.\n",
    "\n",
    "### TP, FP, TN, FN\n",
    "\n",
    "When marking are model's predictions as accurate, we have four ways to classify a token.\n",
    "\n",
    "First, we have TP, or True Positive. This is something that is a specific label and the model predicted that label.\n",
    "\n",
    "Next, we have False Positive. This is a label that was assigned to a token that is incorrect.\n",
    "\n",
    "Next, we have True Negative. This is a token that is not a label and the model correctly did not assign a label to it.\n",
    "\n",
    "Next we have False Negative. This is when a token is a label but the model missed it.\n",
    "\n",
    "### 1. Precision\n",
    "\n",
    "Precision is a measure of how many of the identified entities are correctly classified. In the context of our model, it would represent the proportion of correctly identified PERSON and REALM entities out of all the entities identified as either PERSON or REALM.\n",
    "\n",
    "Here,\n",
    "- True Positives (TP): Entities correctly identified as PERSON or REALM.\n",
    "- False Positives (FP): Entities incorrectly identified as PERSON or REALM (e.g., identifying a mountain as a REALM when it is not labeled as such in the ground truth).\n",
    "\n",
    "### 2. Recall\n",
    "\n",
    "Recall, on the other hand, is a measure of how many of the actual entities are identified by the model. It represents the proportion of correctly identified PERSON and REALM entities out of all the true PERSON and REALM entities in the text.\n",
    "\n",
    "\n",
    "Here,\n",
    "- False Negatives (FN): Entities that are truly PERSON or REALM but were not identified as such by the model (e.g., missing a character's name and not labeling it as PERSON).\n",
    "\n",
    "### Balancing Precision and Recall with the F1-Score\n",
    "\n",
    "In practice, there may be a trade-off between precision and recall. Improving precision might decrease recall, and vice versa. A common way to balance these two measures is to use the F1 score, which is the mean of precision and recall.\n",
    "\n",
    "\n",
    "### When to use Which?\n",
    "\n",
    "When designing models, it is sometimes useful to favor precision over recall. In the real world, this is a metric often used for things like spam detection. You do not want to accidently flag something as spam that is not. To err on the side of caution, you accept a high precision which means all things detected as spam likely are, but you know that some cases of spam will be missed. That's okay because it means the user does not miss the email that has an important meeting, but they may have to delete a few annoying emails still.\n",
    "\n",
    "On the other side of this, we have recall. A good way to think about this in the real world is with cancer screening. A machine learning model would be better if it had high recall at the cost of precision. This is because missing a cancer diagnosis is far more serious than falsely identifying cancer.\n",
    "\n",
    "## 3. Epochs\n",
    "\n",
    "An epoch refers to one complete pass through the entire training dataset. During each epoch, the model's weights are updated to minimize the loss function, which is a measure of the discrepancy between the predicted labels and the actual labels.\n",
    "\n",
    "## Batch Size\n",
    "\n",
    "Sometimes it is difficult to fit all the training data into memory so we pass the data to the model in batches. An epoch is complete only when all batches have been passed to the model during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "589ed8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_hobbit = spacy.load(\"../models/output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e9fa1c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Next day \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " woke early, feeling refreshed and well. He walked along the terraces above the loud-flowing \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bruinen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and watched the pale, cool sun rise above the far mountains, and shine down. Slanting through the thin silver mist; the dew upon the yellow leaves was glimmering, and the woven nets of gossamer twinkled on every bush. Sam walked beside him, saying nothing. but sniffing the air, and looking every now and again with wonder in his eyes at the great heights in the East. The snow was white upon their peaks.</br>     On a seat cut in the stone beside a turn in the path they came upon \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " deep in talk. `Hullo! Good morning!' said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `Feel ready for the great council?'</br>     `I feel ready for anything,' answered \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `But most of all I should like to go walking today and explore the valley. I should like to get into those pine-woods up there.' He pointed away far up the side of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rivendell\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REALM</span>\n",
       "</mark>\n",
       " to the north.</br>     'You may have a chance later,' said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `But we cannot </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = ml_hobbit(text[:1000])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1d17a1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Arwen went to the realm of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Moria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REALM</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text =\"Arwen went to the realm of Moria.\"\n",
    "doc = ml_hobbit(new_text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e6dcb16",
   "metadata": {},
   "source": [
    "# Training with Vectors\n",
    "\n",
    "Training in spaCY 3 is almost exclusively done in the command line. Because we are learning in JupyterLab, we will use `!` before each cell to indicate that this should be run as a command line prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0132dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "../data/config_vec.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_vec.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ../data/base_config_vec.cfg ../data/config_vec.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b45017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: ../models/output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-08-04 01:55:51,232] [INFO] Set up nlp object from config\n",
      "[2023-08-04 01:55:51,240] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-08-04 01:55:51,243] [INFO] Created vocabulary\n",
      "/home/wjbmattingly/anaconda3/lib/python3.7/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.6.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[2023-08-04 01:55:52,782] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-08-04 01:55:52,782] [INFO] Finished initializing nlp object\n",
      "[2023-08-04 01:55:53,189] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     24.20    0.00    0.00    0.00    0.00\n",
      "  2     200          6.53    697.55   96.19   96.19   96.19    0.96\n",
      "  5     400          5.05     26.21   95.24   95.24   95.24    0.95\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ../data/config_vec.cfg --output ../models_vec/output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53da5a0b",
   "metadata": {},
   "source": [
    "# Using the Model\n",
    "\n",
    "We can now use this model by opening it as we would any other model. It is saved to disk in `../models_vec/output-best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "726ef81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_hobbit = spacy.load(\"../models_vec/output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8584a457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Next day \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " woke early, feeling refreshed and well. He walked along the terraces above the loud-flowing \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bruinen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and watched the pale, cool sun rise above the far mountains, and shine down. Slanting through the thin silver mist; the dew upon the yellow leaves was glimmering, and the woven nets of gossamer twinkled on every bush. Sam walked beside him, saying nothing. but sniffing the air, and looking every now and again with wonder in his eyes at the great heights in the East. The snow was white upon their peaks.</br>     On a seat cut in the stone beside a turn in the path they came upon \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " deep in talk. `Hullo! Good morning!' said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bilbo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `Feel ready for the great council?'</br>     `I feel ready for anything,' answered \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Frodo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `But most of all I should like to go walking today and explore the valley. I should like to get into those pine-woods up there.' He pointed away far up the side of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rivendell\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REALM</span>\n",
       "</mark>\n",
       " to the north.</br>     'You may have a chance later,' said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gandalf\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". `But we cannot </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = ml_hobbit(text[:1000])\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf2aad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Arwen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " went to the realm of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Moriaa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "?.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text =\"Arwen went to the realm of Moriaa?.\"\n",
    "doc = ml_hobbit(new_text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3b5f0d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'PERSON': 442, 'REALM': 105})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter()\n",
    "for item in training_data:\n",
    "    for ent in item['ents']:\n",
    "        label_counts[ent['label']] += 1\n",
    "\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74eb348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
